name: AISIS â€“ Class Schedule (All Available Terms)

on:
  workflow_dispatch:
    inputs:
      scrape_mode:
        description: 'Scrape mode'
        required: false
        default: 'year'
        type: choice
        options:
          - current
          - future
          - all
          - year
  schedule:
    # Run weekly on Sundays at 2 AM UTC
    - cron: '0 2 * * 0'

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Download previous baselines
        # See README.md "Baseline Tracking and Regression Detection" section
        # Downloads baseline-{term}.json files from previous runs for comparison
        uses: actions/download-artifact@v4
        with:
          name: baselines
          path: logs/baselines/
        continue-on-error: true  # Don't fail if no previous baseline exists

      - name: Run scraper (year mode by default)
        env:
          AISIS_USERNAME: ${{ secrets.AISIS_USERNAME }}
          AISIS_PASSWORD: ${{ secrets.AISIS_PASSWORD }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          DATA_INGEST_TOKEN: ${{ secrets.DATA_INGEST_TOKEN }}
          GOOGLE_SERVICE_ACCOUNT: ${{ secrets.GOOGLE_SERVICE_ACCOUNT }}
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
          # Scrape mode: 'year' by default (scrapes all terms in current academic year)
          # Can be overridden via workflow input to: current, future, all, year
          AISIS_SCRAPE_MODE: ${{ github.event.inputs.scrape_mode || 'year' }}
          # Optional: Performance tuning (default: 2000)
          # SUPABASE_CLIENT_BATCH_SIZE: '2000'
          # Optional: Regression detection (defaults: 5.0, true)
          # BASELINE_DROP_THRESHOLD: '5.0'
          # BASELINE_WARN_ONLY: 'true'
        run: npm start
      
      - name: Upload baselines for next run
        # See README.md "Baseline Tracking and Regression Detection" section
        # Saves baseline-{term}.json files for comparison in future runs
        uses: actions/upload-artifact@v4
        if: always()  # Upload even if scraper fails
        with:
          name: baselines
          path: logs/baselines/
          retention-days: 90  # Keep baselines for 90 days
