name: AISIS – Class Schedule (Full Academic Year)

on:
  workflow_dispatch:
    inputs:
      target_year:
        description: 'Target academic year (e.g., 2025)'
        required: false
        type: string
      require_baselines:
        description: 'Require baselines (fail if missing)'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm install

      - name: Determine target year
        id: year
        run: |
          if [ -n "${{ github.event.inputs.target_year }}" ]; then
            echo "TARGET_YEAR=${{ github.event.inputs.target_year }}" >> $GITHUB_ENV
            echo "Using input year: ${{ github.event.inputs.target_year }}"
          else
            CURRENT_YEAR=$(date +%Y)
            echo "TARGET_YEAR=$CURRENT_YEAR" >> $GITHUB_ENV
            echo "Using current year: $CURRENT_YEAR"
          fi

      - name: Download previous baselines
        id: download-baselines
        # Downloads baseline-{term}.json files from previous runs for comparison
        uses: actions/download-artifact@v4
        with:
          name: baselines
          path: logs/baselines/
        continue-on-error: true  # Don't fail here; we check below

      - name: Check baselines availability
        # When REQUIRE_BASELINES is true and baselines failed to download,
        # log a clear error and fail fast before any ingestion
        run: |
          REQUIRE_BASELINES="${{ github.event.inputs.require_baselines || 'true' }}"
          DOWNLOAD_OUTCOME="${{ steps.download-baselines.outcome }}"
          
          echo "Baselines download outcome: $DOWNLOAD_OUTCOME"
          echo "REQUIRE_BASELINES: $REQUIRE_BASELINES"
          
          if [[ "$REQUIRE_BASELINES" == "true" && "$DOWNLOAD_OUTCOME" != "success" ]]; then
            echo ""
            echo "❌ FATAL: Baselines artifact 'baselines' missing; aborting schedule ingest to avoid data loss."
            echo ""
            echo "The workflow is configured with REQUIRE_BASELINES=true, but no baselines artifact was found."
            echo "This typically means:"
            echo "  - This is the first run (baselines don't exist yet)"
            echo "  - Previous runs failed to upload baselines"
            echo "  - The artifact expired (retention is 90 days)"
            echo ""
            echo "Solutions:"
            echo "  1. For first-time setup: Re-run with require_baselines=false"
            echo "  2. Check previous workflow runs for baselines artifact"
            echo "  3. Manually restore baselines from a known good state"
            exit 1
          fi
          
          if [[ "$DOWNLOAD_OUTCOME" == "success" ]]; then
            echo "✅ Baselines downloaded successfully"
            ls -la logs/baselines/ || true
          else
            echo "ℹ️  No baselines found (first run or expired). Proceeding without baselines."
          fi

      - name: Run full year schedule scraper
        env:
          AISIS_USERNAME: ${{ secrets.AISIS_USERNAME }}
          AISIS_PASSWORD: ${{ secrets.AISIS_PASSWORD }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          DATA_INGEST_TOKEN: ${{ secrets.DATA_INGEST_TOKEN }}
          GOOGLE_SERVICE_ACCOUNT: ${{ secrets.GOOGLE_SERVICE_ACCOUNT }}
          SPREADSHEET_ID: ${{ secrets.SPREADSHEET_ID }}
          TARGET_YEAR: ${{ env.TARGET_YEAR }}
          # Require baselines for regression detection (default: true)
          # Set to false for first-time runs or when intentionally resetting baselines
          REQUIRE_BASELINES: ${{ github.event.inputs.require_baselines || 'true' }}
          # Optional: Performance tuning (default: 2000)
          # SUPABASE_CLIENT_BATCH_SIZE: '2000'
        run: node src/scrape-full-year.js
      
      - name: Upload baselines for next run
        # Saves baseline-{term}.json files for comparison in future runs
        uses: actions/upload-artifact@v4
        if: always()  # Upload even if scraper fails
        with:
          name: baselines
          path: logs/baselines/
          retention-days: 90  # Keep baselines for 90 days

      - name: Upload schedule logs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: schedule-logs-${{ env.TARGET_YEAR }}
          path: |
            logs/schedule-all-terms-*.json
            data/schedules-full-year-*.json
          retention-days: 30
